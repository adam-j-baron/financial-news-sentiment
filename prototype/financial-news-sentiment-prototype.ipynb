{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef40246e",
   "metadata": {},
   "source": [
    "# Financial News Sentiment\n",
    "\n",
    "When working with LLMs, I've often spend a lot of time on prompt engineering.  It's a bit like going to the eye doctor since  the question \"Is this one better than that one?\" keeps getting asked, for each system prompt variant.  With this notebook, you're able to run many more tests at scale, so you are no longer relying on just one datapoint to compare two system prompts.\n",
    "\n",
    "The goal of this notebook is to explore how a state-of-the-art general purpose LLM performs compared a highly specialized Transformer model on the task of classifying sentiment in financial news.  The actual `ollama_model` and the `ollama_system_prompt` are configurable, via notebook parameters, so different permutations can be explored.\n",
    "\n",
    "This notebook also connects to live news data and assigns a sentiment from the models, allowing for the possiblitiy of human evaluators to be able to judge how each model performed.\n",
    "\n",
    "<u>The notebook flows in these steps:</u>\n",
    "1. Load Financial Sentiment Evaluation Dataset\n",
    "    - Financial PhraseBank\n",
    "2. Load Sentiment Models\n",
    "    - Transformer: FinBERT\n",
    "    - LLM: Qwen3\n",
    "3. Evaluate Models\n",
    "4. Retrieve Live News Articles\n",
    "5. Assign Sentiment to Live News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d306d7e3",
   "metadata": {},
   "source": [
    "### Notebook Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13df71e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_url = \"http://localhost:11434\" # Default Ollama URL\n",
    "ollama_model =  \"qwen3\"\n",
    "ollama_system_prompt =  \"You are a financial sentiment analysis AI. Classify the following text as 'positive', 'negative', or 'neutral'. Respond with only one word, the chosen sentiment label. Do not provide any other text or explanation.\"\n",
    "\n",
    "num_sentences = 100 # Number of sentences to use from evaluation set\n",
    "shuffle_seed = 23 # Shuffle the evaluation set of better distribution of labels; shuffle seed is hardcoded here for reproducibility\n",
    "\n",
    "live_news_ticker = \"YELP\" # Pull the latest news for this stock\n",
    "num_live_articles = 10 # How many live news articles to pull for that stock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08cdfcb",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadfb750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from newspaper import Article\n",
    "import random\n",
    "import requests\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import yfinance as yf\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee31a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed for FinBERT initialization\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e0bd86",
   "metadata": {},
   "source": [
    "### Load the Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbb70ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the ZIP file\n",
    "url = \"https://huggingface.co/datasets/takala/financial_phrasebank/resolve/main/data/FinancialPhraseBank-v1.0.zip\"\n",
    "response = requests.get(url)\n",
    "zip_file = zipfile.ZipFile(io.BytesIO(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf92ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the specific file: Sentences_AllAgree.txt (note: it's inside FinancialPhraseBank-v1.0 folder)\n",
    "file_path = \"FinancialPhraseBank-v1.0/Sentences_AllAgree.txt\"\n",
    "with zip_file.open(file_path) as f:\n",
    "    lines = f.read().decode('ISO-8859-1').splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9bcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afffa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector of sentences and a vector of labels\n",
    "# Note that Transformer models use numbers (0, 1, 2) for classification labels instead of text (negative, neutral, positive), so conversion is necessary\n",
    "\n",
    "data_tuples = []\n",
    "label_map = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "id_to_label = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "\n",
    "for line in lines:\n",
    "    if '@' in line:\n",
    "        sentence, label_str = line.rsplit('@', 1)\n",
    "        sentence = sentence.strip()\n",
    "        label_str = label_str.strip()\n",
    "        if label_str in label_map:\n",
    "            data_tuples.append((sentence, label_map[label_str]))\n",
    "\n",
    "# Add Shuffling to better balance label distribution\n",
    "random.seed(shuffle_seed) # Hardcoded seed for reproducibility\n",
    "random.shuffle(data_tuples)\n",
    "\n",
    "sentences = [t[0] for t in data_tuples]\n",
    "labels = [t[1] for t in data_tuples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b18f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9cec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b94e19",
   "metadata": {},
   "source": [
    "### Load Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127b36b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinBERTModel:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "        self.model.to(device)\n",
    "        self.name = \"FinBERT\"\n",
    "        # FinBERT has a different label order, so we define a mapping\n",
    "        self.finbert_label_map = {0: 2, 1: 0, 2: 1} # 0 (positive) -> 2 (positive), 1 (negative) -> 0 (negative), 2 (neutral) -> 1 (neutral)\n",
    "\n",
    "    def predict(self, sentence):\n",
    "        inputs = self.tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(**inputs).logits\n",
    "        \n",
    "        # Get the model's predicted class ID\n",
    "        predicted_class_id = logits.argmax(dim=-1).item()\n",
    "        \n",
    "        # Map the model's class ID to our dataset's label ID\n",
    "        return self.finbert_label_map[predicted_class_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91439c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "finbert_model = FinBERTModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8b1d0a",
   "metadata": {},
   "source": [
    "### Load Ollama Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a6f255",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OllamaModel:\n",
    "    def __init__(self, url, model_name):\n",
    "        self.chat_model = ChatOllama(base_url=url, model=model_name, reasoning=False) # Turn off reasoning for quicker response without <think> phase\n",
    "        self.system_prompt = ollama_system_prompt\n",
    "        self.name = model_name\n",
    "        self.label_map = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "\n",
    "    def predict(self, sentence):\n",
    "        messages = [\n",
    "            SystemMessage(content=self.system_prompt),\n",
    "            HumanMessage(content=sentence)\n",
    "        ]\n",
    "        response = self.chat_model.invoke(messages)\n",
    "        predicted_label_string = response.content.lower()\n",
    "        \n",
    "        # Return None if the model's response is not a valid label\n",
    "        if predicted_label_string not in self.label_map:\n",
    "            return None\n",
    "        \n",
    "        return self.label_map[predicted_label_string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ecaf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_model = OllamaModel(ollama_url, ollama_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6ffab0",
   "metadata": {},
   "source": [
    "### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34999e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, sentences, labels, num_sentences):\n",
    "    \"\"\"\n",
    "    Evaluates a sentiment classification model and returns a dictionary of metrics.\n",
    "    \"\"\"\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    invalid_responses = 0\n",
    "\n",
    "    print(f\"Running classification with {model.name}...\")\n",
    "    print(f\"Evaluating {num_sentences} sentences.\")\n",
    "    print(\"---\")\n",
    "\n",
    "    for i in range(min(num_sentences, len(sentences))):\n",
    "        sentence = sentences[i]\n",
    "        actual_label = labels[i]\n",
    "        predicted_class_id = model.predict(sentence)\n",
    "\n",
    "        # Only append to lists if the prediction is valid\n",
    "        if predicted_class_id is not None:\n",
    "            true_labels.append(actual_label)\n",
    "            predicted_labels.append(predicted_class_id)\n",
    "        else:\n",
    "            invalid_responses += 1\n",
    "\n",
    "    # Handle the case where all responses are invalid\n",
    "    if not true_labels:\n",
    "        return {\n",
    "            'model_name': model.name,\n",
    "            'accuracy': 0.0,\n",
    "            'classification_report': 'No valid predictions were made.',\n",
    "            'invalid_responses': invalid_responses\n",
    "        }\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    report = classification_report(\n",
    "        true_labels,\n",
    "        predicted_labels,\n",
    "        target_names=list(label_map.keys()),\n",
    "        labels=[0, 1, 2],\n",
    "        zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Return metrics in a structured format\n",
    "    return {\n",
    "        'model_name': model.name,\n",
    "        'accuracy': accuracy,\n",
    "        'classification_report': report,\n",
    "        'invalid_responses': invalid_responses\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614598bf",
   "metadata": {},
   "source": [
    "### Evaluate Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b2f0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "finbert_metrics = evaluate_model(finbert_model, sentences, labels, num_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e428a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{finbert_metrics['model_name'].upper()} EVALUATION SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Accuracy: {finbert_metrics['accuracy']:.4f}\\n\")\n",
    "print(f\"Invalid Responses: {finbert_metrics['invalid_responses']}/{num_sentences}\\n\")\n",
    "print(\"Classification Report:\\n\")\n",
    "print(finbert_metrics['classification_report'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad0f35e",
   "metadata": {},
   "source": [
    "### Evaluate LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bc00b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_metrics = evaluate_model(ollama_model, sentences, labels, num_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0282c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{ollama_metrics['model_name'].upper()} EVALUATION SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Accuracy: {ollama_metrics['accuracy']:.4f}\\n\")\n",
    "print(f\"Invalid Responses: {ollama_metrics['invalid_responses']}/{num_sentences}\\n\")\n",
    "print(\"Classification Report:\\n\")\n",
    "print(ollama_metrics['classification_report'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7060f8",
   "metadata": {},
   "source": [
    "### Retrieve Live News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14794107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_news(ticker, max_articles=5):\n",
    "    \"\"\"\n",
    "    Get recent news articles for a stock ticker\n",
    "    \n",
    "    Args:\n",
    "        ticker (str): Stock ticker symbol (e.g., 'MSFT', 'AAPL')\n",
    "        max_articles (int): Maximum number of articles to return\n",
    "    \n",
    "    Returns:\n",
    "        list: List of dictionaries containing article data\n",
    "    \"\"\"\n",
    "\n",
    "    # Get high-level news summary and article links from Yahoo! Finance\n",
    "    stock = yf.Ticker(ticker)\n",
    "    news = stock.news\n",
    "    \n",
    "    articles = []\n",
    "\n",
    "    for i, item in enumerate(news[:max_articles]):\n",
    "        try:\n",
    "            url = item['content']['canonicalUrl']['url']\n",
    "            \n",
    "            # Follow article link to retreive full article content \n",
    "            article = Article(url)\n",
    "            article.download()\n",
    "            article.parse()\n",
    "            \n",
    "            article_data = {\n",
    "                'id': item['content']['id'],\n",
    "                'pub_date': item['content']['pubDate'],\n",
    "                'url': url,\n",
    "                'title': item['content']['title'],\n",
    "                'summary': item['content'].get('summary', ''),\n",
    "                'full_text': article.text\n",
    "            }\n",
    "            \n",
    "            articles.append(article_data)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Could not parse article {i+1}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757f0f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_articles = get_stock_news(live_news_ticker, num_live_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ca3ae7",
   "metadata": {},
   "source": [
    "### Classify Sentiment on Live News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f305d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in stock_articles:\n",
    "\n",
    "    # Combined article title and body for maximum information\n",
    "    title_body = article['title'] + \"\\n\" + article['full_text']\n",
    "\n",
    "    # Run Transformer model to classify news\n",
    "    finbert_sent = id_to_label[finbert_model.predict(title_body)]\n",
    "\n",
    "    # Run LLM model to classify news\n",
    "    ollama_sent = id_to_label[ollama_model.predict(title_body)]\n",
    "\n",
    "    print(f\"{finbert_model.name}: {finbert_sent}\")\n",
    "    print(f\"{ollama_model.name}: {ollama_sent}\")\n",
    "    print(f\"Title: {article['title']}\")\n",
    "    print(f\"Body: {article['full_text'][:250].replace('\\n', ' ')}...\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
